
<!DOCTYPE html>
<html lang="en">

<head>
  <title>Racial Bias in AI&mdash;</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  <link href="https://fonts.googleapis.com/css?family=DM+Serif+Display:400,400i|Roboto+Mono&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="css/animate.css">
  <link rel="stylesheet" href="css/owl.carousel.min.css">
  <link rel="stylesheet" href="css/jquery.fancybox.min.css">


  <link rel="stylesheet" href="fonts/ionicons/css/ionicons.min.css">
  <link rel="stylesheet" href="fonts/fontawesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
  <link rel="stylesheet" href="css/aos.css">
  <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.css">

  <!-- Theme Style -->
  <link rel="stylesheet" href="css/style.css">

</head>

<body>

  <header role="banner">
    <nav class="navbar navbar-expand-lg  bg-dark">
      <div class="container-fluid">
        <a class="navbar-brand " href="index.html">Racial Bias in AI</a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample05"
          aria-controls="navbarsExample05" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

   
      
        <div class="collapse navbar-collapse" id="navbarsExample05">
          <ul class="navbar-nav pl-md-5 ml-auto">
            <li class="nav-item">
              <a class="nav-link active" href="index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="COMPAS.html">COMPAS</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="ABFERET.html">Algorithmic Bias In Facial Recognition
              </a>
              <li class="nav-item">
                <a class="nav-link" href="FERETCJ.html">Facial Recognition & Criminal Justice</a>
              </li>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AID.html">AI Ethics & Discrimination</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AIBH.html">Algorithmic Bias in Healthcare </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AIBR.html">Algorithmic Bias in Recruiting </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="solution.html">General Solution to Racial Bias in AI </a>
            </li>
          </ul>

        </div>
      </div>
  

          <div class="navbar-nav ml-auto">
            <form method="post" class="search-form">
              <span class="icon ion ion-search"></span>
              <input type="text" class="form-control" placeholder="Search...">
            </form>
          </div>

        </div>
      </div>
    </nav>
  </header>
  <!-- END header -->

  <div class="slider-item overlay" data-stellar-background-ratio="0.5"
    style="background-image: url('images/lizbackground.jpg');">
    <div class="container">
      <div class="row slider-text align-items-center justify-content-center text-center">
        <div class="col-lg-12 col-sm-12">
          <p class="text-white mb-4" data-aos="fade-up" data-aos-delay="50"> ALGORITHMIC BIAS WITHIN FACIAL RECOGNITION TECHNOLOGY </p></strong>
          <p class="custom-breadcrumbs" data-aos="fade-up" data-aos-delay="50"><a href="index.html">Home</a> 
        </div>
      </div>
    </div>
  </div>

  
        
           
            

            <div class="section portfolio-section">
              <div class="container">
                <div class="row mb-5 justify-content-center" data-aos="fade-up">
                  <div class="col-md-8 text-center">
                    <p>Facial recognition technology (FRT) is a biometric Artificial Intelligence software utilized by private and federal establishments. The technology poses many risks to those of color as it ubiquitously misidentifies their facial features in relation to their white counterparts. In using this technology, law enforcement holds the ability to identify, process, and possess erroneous data. 
                    </p>
                    <p>Many controversies have surfaced regarding the role of facial recognition in law enforcement. FRT performs poorly on people of color and women as testing datasets are 77% male and 83% white, and the technology misidentifies African American and Asian faces 10 to 100 times more than Caucasian faces . The Detroit Police Department uses FRT and reported a 1 96% inaccuracy rate on a dataset consisting of 68 out of 70 people of color, with the remaining persons identities left undisclosed (Gilbert, 2020). Furthermore, the technology is erroneous and does not assist with preventing crime; cases would not be solved 96% of the time if law enforcement solely relied on FRT software . Three wrongful convictions have occurred on the 2 basis of FRT. Michael Oliver, Robert Williams, and Nijeer Parks are all Black men who have suffered the negative impact of algorithmic bias. Michael Oliver’s wrongful arrest during the summer of 2019 was followed by Detroit’s implementation of safeguards and limits on the use of FRT in September of 2020. Conversely, the following summer of 2020, Robert Williams was misidentified and wrongfully arrested based on the technology, even with strict limits in place </p>
                    <p>Various facial recognition companies utilize flawed algorithms that misidentify people of color, therefore accentuating pre-existing racial disparities. Clearview AI is one of the most controversial FRT companies and is currently being sued by California immigrant rights groups. The company has partnerships with police departments and the Bureau of Immigration and Customs Enforcement, yet police departments fail to disclose their use of Clearview AI. The company is known to deploy biased algorithms and has recently been banned in New Jersey by the state attorney, Gurbir S. Grewal . The Philadelphia Police Department has also recently 4 experimented with Clearview AI, facing public reverberations as Philadelphia’s population is 40.1% Black (Non-Hispanic) and 7.34% Asian (Non-Hispanic). 
                    </p>
                    <p>Overall, FRT negatively impacts communities of color as it reinforces bias, wrongful convictions, and unconstitutional surveillance. The technology predominantly endangers marginalized groups through its erroneous practice and biased algorithms. US legislators must take imperative action to prevent algorithmic bias. 
                    </p>
                    <p> Such use of facial recognition software elucidates a precedent for preventative legislation. On June 25, 2020, Senators Markey and Merkeley introduced the Facial Recognition and Biometric Technology Moratorium Act. The act will work to limit and prohibit the use of facial recognition technology and biometrics in law enforcement. Nationwide, bans and moratoriums on the software have been implemented on local levels. San Francisco was the first US city to ban facial recognition in 2019. Legislation such as the Facial Recognition and Biometric Technology Moratorium Act must be implemented nationwide to preserve constitutional rights and eliminate algorithmic bias. 
                    </p>
                    <p> Furthermore, the most effective practice to combat algorithmic bias is the use of representative data sets. If the makeup of testing datasets is predominantly Caucaisian, the algorithm will noticeably perform poorly on people of color as it has not been trained on such facial features. Representative datasets allow for algorithms to effectively train and process African American and Asian faces as well as Caucausian faces. Moreover, programmers should reflect the population the algorithm [they are writing] will serve: Caucausian people cannot write algorithms for people of color, as their biases will inadvertently be incorporated into the algorithms. 
                    </p>
                    <p>Through the implementation of preventative legislation and representative testing and programming, algorithmic bias within FRT can be minimized. Such legislation in the form of a ban or a moratorium on the use of FRT is effective in reducing wrongful convictions and unlawful surveillance. In addition, representation in programming and data testing bolsters the potency of facial recognition technology. Such measures are imperative in obstructing the software’s bias and fortifying its ethicality.
                    </p>
                    <p>References 
                      Gilbert, B. (2020, June 30). Facial-recognition software fails to correctly identify people '96% of the time,' Detroit police chief says. Business Insider. Retrieved 20 April, 2021, from https://www.businessinsider.com/facial-recognition-fails-96-of-the-time-detroit-police-ch ief-2020-6 
                      Singer, N., & Cade, M. (2019, December 19). Many Facial-Recognition Systems Are Biased, Says U.S. Study. The New York Times. 
                      www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html 
                      Hill, K. (2020, January 25). New Jersey Bars Police From Using Clearview Facial Recognition App. The New York Times. 
                      www.nytimes.com/2020/01/24/technology/clearview-ai-new-jersey.html 
                      Hill, K. (2020, June 24). Wrongfully Accused by an Algorithm. The New York Times. www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html
                      </p>
          </figure>
        </div>
        <div class="col-md-5 mr-auto" data-aos="fade-up" data-aos-delay="">
  
  <!-- END section -->

  <!-- END .block-4 -->
  </div>

  

  
  <!-- END footer -->

  <!-- loader -->
  <div id="loader" class="show fullscreen"><svg class="circular" width="48px" height="48px">
      <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee" />
      <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
        stroke="#ffc107" /></svg></div>

  <script src="js/jquery-3.2.1.min.js"></script>
  <script src="js/jquery-migrate-3.0.1.min.js"></script>
  <script src="js/popper.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/owl.carousel.min.js"></script>
  <script src="js/jquery.waypoints.min.js"></script>
  <script src="js/jquery.fancybox.min.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/aos.js"></script>
  <script src="js/main.js"></script>
</body>

</html>