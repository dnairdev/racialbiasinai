
<!DOCTYPE html>
<html lang="en">

<head>
  <title>Racial Bias in AI&mdash;</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  <link href="https://fonts.googleapis.com/css?family=DM+Serif+Display:400,400i|Roboto+Mono&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="css/animate.css">
  <link rel="stylesheet" href="css/owl.carousel.min.css">
  <link rel="stylesheet" href="css/jquery.fancybox.min.css">


  <link rel="stylesheet" href="fonts/ionicons/css/ionicons.min.css">
  <link rel="stylesheet" href="fonts/fontawesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
  <link rel="stylesheet" href="css/aos.css">
  <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.css">

  <!-- Theme Style -->
  <link rel="stylesheet" href="css/style.css">

</head>

<body>

  <header role="banner">
    <nav class="navbar navbar-expand-lg  bg-dark">
      <div class="container-fluid">
        <a class="navbar-brand " href="index.html">Racial Bias in AI</a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample05"
          aria-controls="navbarsExample05" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

   
        <div class="collapse navbar-collapse" id="navbarsExample05">
          <ul class="navbar-nav pl-md-5 ml-auto">
            <li class="nav-item">
              <a class="nav-link active" href="index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="COMPAS.html">COMPAS</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="ABFERET.html">Algorithmic Bias In Facial Recognition
              </a>
              <li class="nav-item">
                <a class="nav-link" href="FERETCJ.html">Facial Recognition & Criminal Justice</a>
              </li>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AID.html">AI Ethics & Discrimination</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AIBH.html">Algorithmic Bias in Healthcare </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AIBR.html">Algorithmic Bias in Recruiting </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="solution.html">General Solution to Racial Bias in AI </a>
            </li>
          </ul>

        </div>
      </div>
    </nav>

          <div class="navbar-nav ml-auto">
            <form method="post" class="search-form">
              <span class="icon ion ion-search"></span>
              <input type="text" class="form-control" placeholder="Search...">
            </form>
          </div>

        </div>
      </div>
    </nav>
  </header>
  <!-- END header -->

  <div class="slider-item overlay" data-stellar-background-ratio="0.5"
    style="background-image: url('images/barsrisk.jpg');">
    <div class="container">
      <div class="row slider-text align-items-center justify-content-center text-center">
        <div class="col-lg-12 col-sm-12">
          <p class="text-white mb-4" data-aos="fade-up" data-aos-delay="50"> WHERE IS COMPAS POINTING TO?: STUDYING THE “ARTIFICIALLY INTELLIGENT” RISK ASSESSMENT INSTRUMENT </p></strong>
          <p class="custom-breadcrumbs" data-aos="fade-up" data-aos-delay="50"><a href="index.html">Home</a> 
        </div>
      </div>
    </div>
  </div>

  
        
           
            

            <div class="section portfolio-section">
              <div class="container">
                <div class="row mb-5 justify-content-center" data-aos="fade-up">
                  <div class="col-md-8 text-center">
                    
                    <p>The ubiquity of artificial intelligence has presented itself in the criminal justice system. Uses of artificial intelligence in the criminal justice system present from surveillance in predictive policing to criminalizing algorithms that determine recidivism. However, there has been some missteps between artificial intelligence and the criminal justice system. This abstract explores the failures of crimalizing algorithms in artificial intelligence and its consequences, employing COMPAS (Correctional Offender Management Profiling for Alternative Sanctions), a risk assemention instrument (RAI), as a case study. It then provides a possible solution and attempts to help prevent these failures. 
                    </p>
                    <p>The disconnections between artificial intelligence and the criminal justice systems, stems from algorithmic bias that amplifies current racial prejudice that already exists on the physical level. From suspicion levels to incarceration or arrest-related deaths, racial disparities in the criminal justice system affect Black Americans more so than their White counterparts. Racial disparities in artificially intelligent risk assessment instruments can detrimentally influence sentencing and parole determination for Black people. In the analysis of COMPAS by researchers at ProPublica, the following was found: “Black defendants were often predicted to be at a higher risk of recidivism than they actually were. (Black defendants who did not recidivate over a two-year period were nearly twice as likely to be misclassified as higher risk compared to their white counterparts (45 percent vs. 23 percent)); Black defendants were also twice as likely as white defendants to be misclassified as being a higher risk of violent recidivism. And white violent recidivists were 63 percent more likely to have been misclassified as a low risk of violent recidivism, compared with black violent recidivists; and The violent recidivism analysis also showed that even when controlling for prior crimes, future recidivism, age, and gender, black defendants were 77 percent more likely to be assigned higher risk scores than white defendants” (Larson et al.). It is clear that due to the amplification of racist systemic bias in the physical world in determining if a criminal will be violent or return to prison,  that “COMPAS” may not be pointing artificial intelligence in the criminal justice system in the right direction. Criminal profiling can be a life or death situation for Black Americans. Unfortunately, COMPAS is used by many police departments in America. However, there is hope that maybe we can move forward in the right direction. 
                    </p>
                    <p>Three possible solutions that would need to work contingently in order to create a more ethical use of criminal profiling and predictive recidivism artificial intelligence: 1) companies that use AI must be legally audited by an algorithmic accountability standard, 2) the introduction of a practice using formulaic “cushion” (a statistical crutch to serve equalize a disproportionality) in machine learning to help decrease algorithmic bias, and 3) a continued broadening of the dialogue between the developers of artificial intelligence and the end-receivers it is used with and on. </p>
                    <p>In conclusion, transparency is critical for the implementation of ethical AI and its development. With clarity and revision, we can fine tune these algorithms. Opening and maintaining a dialogue between both those who develop artificial intelligence and those who are affected by it will be our only way of creating a just society, artificially and physically. 
                    </p>
                    <p> 
                      Works Cited
                      Larson, Jeff, et al. How We Analyzed the COMPAS Recidivism Algorithm. 23 May 2016, 
                      www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm. 
                      
                      Park, Andrew Lee, et al. “Injustice Ex Machina: Predictive Algorithms in Criminal Sentencing.” UCLA 
                        Law Review, 21 Sept. 2019, www.uclalawreview.org/injustice-ex-machina-predictive-
                      algorithms-in-criminal-sentencing/. 
                      
                      
                      </p>
          </figure>
        </div>
        <div class="col-md-5 mr-auto" data-aos="fade-up" data-aos-delay="">
          
      
  
  <!-- END section -->

  <!-- END .block-4 -->
  </div>

  

  
  <!-- END footer -->

  <!-- loader -->
  <div id="loader" class="show fullscreen"><svg class="circular" width="48px" height="48px">
      <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee" />
      <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
        stroke="#ffc107" /></svg></div>

  <script src="js/jquery-3.2.1.min.js"></script>
  <script src="js/jquery-migrate-3.0.1.min.js"></script>
  <script src="js/popper.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/owl.carousel.min.js"></script>
  <script src="js/jquery.waypoints.min.js"></script>
  <script src="js/jquery.fancybox.min.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/aos.js"></script>
  <script src="js/main.js"></script>
</body>

</html>