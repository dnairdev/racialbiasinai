
<!DOCTYPE html>
<html lang="en">

<head>
  <title> Solution &mdash; Mitigating discriminatory bias in AI</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  <link href="https://fonts.googleapis.com/css?family=DM+Serif+Display:400,400i|Roboto+Mono&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="css/animate.css">
  <link rel="stylesheet" href="css/owl.carousel.min.css">
  <link rel="stylesheet" href="css/jquery.fancybox.min.css">


  <link rel="stylesheet" href="fonts/ionicons/css/ionicons.min.css">
  <link rel="stylesheet" href="fonts/fontawesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
  <link rel="stylesheet" href="css/aos.css">
  <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.css">

  <!-- Theme Style -->
  <link rel="stylesheet" href="css/style.css">

</head>

<body>

  <header role="banner">
    <nav class="navbar navbar-expand-lg  bg-dark">
      <div class="container-fluid">
        <a class="navbar-brand " href="index.html">Racial Bias in AI</a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample05"
          aria-controls="navbarsExample05" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

   
      
      
        <div class="collapse navbar-collapse" id="navbarsExample05">
          <ul class="navbar-nav pl-md-5 ml-auto">
            <li class="nav-item">
              <a class="nav-link active" href="index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="COMPAS.html">COMPAS</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="ABFERET.html">Algorithmic Bias In Facial Recognition
              </a>
              <li class="nav-item">
                <a class="nav-link" href="FERETCJ.html">Facial Recognition & Criminal Justice</a>
              </li>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AID.html">AI Ethics & Discrimination</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AIBH.html">Algorithmic Bias in Healthcare </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="AIBR.html">Algorithmic Bias in Recruiting </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="solution.html">General Solution to Racial Bias in AI </a>
            </li>
          </ul>

          <div class="navbar-nav ml-auto">
            <form method="post" class="search-form">
              <span class="icon ion ion-search"></span>
              <input type="text" class="form-control" placeholder="Search...">
            </form>
          </div>

        </div>
      </div>
    </nav>
  </header>
  <!-- END header -->

  <div class="slider-item overlay" data-stellar-background-ratio="0.5"
    style="background-image: url('images/B3-DD125_BIAS02_P_20190211152910.jpg');">
    <div class="container">
      <div class="row slider-text align-items-center justify-content-center text-center">
        <div class="col-lg-12 col-sm-12">
          <p class="text-white mb-4" data-aos="fade-up" data-aos-delay="50"> MITIGATING DISCRIMINATORY BIAS IN AI: A GENERAL TAKE </p></strong>
          <p class="custom-breadcrumbs" data-aos="fade-up" data-aos-delay="50"><a href="index.html">Home</a> 
        </div>
      </div>
    </div>
  </div>

  
        
           
            

            <div class="section portfolio-section">
              <div class="container">
                <div class="row mb-5 justify-content-center" data-aos="fade-up">
                  <div class="col-md-8 text-center">
                    
                    <p>Thus far, problems surrounding algorithmic bias in AI have been extensively evidenced, nevertheless, solutions must be put forward to further the use of AI in society. Without a doubt, identifying solutions to counter discriminatory bias is imperative to bettering society's perception of Artificial Intelligence and maintaining the safety of humans who interact with intelligent software. 
                    </p>
                    <p>It is important to note that bias in algorithms that interact with human data is not necessarily discriminatory in a harmful way towards certain groups of people. A possible example of this is AI used for employing possible candidates at a construction company. An employer in the construction industry who is looking to hire a labourer will make sure to program their AI algorithm to weed out applicants with physical disabilities which would hinder the building process. This is a very logical and understandable bias to program into the AI's algorithm in this situation. Suppose the same software was to be used for hiring applicants for a desk position; the bias against those with physical disabilities would become discriminatory in a harmful way towards those with physical disabilities. Indeed, understanding the context for which an AI algorithm was conceived is crucial to distinguishing harmful biases from helpful and harmless biases.
                    </p>
                    <p>Furthermore, AI developers and analysts must remember at all times that an AI's algorithm is only as unbiased as the data fed into it. That is to say that discrimination and bias in AI are directly and only caused by biased and discriminatory data sets. Therefore, AI algorithms can easily reflect the prejudices held in society and communities. Consequently, AI developers must first identify which moral principles are to be reflected in the algorithm's operation before deploying the AI software. Recently, there has been an effort to codify AI principles such as the Asilomar AI Principles and The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems, although the evolution of these principles is expected to come with the progression of our comprehension of AI. 
                    </p>
                    <p>A possible solution for mitigating bias in AI is using another AI algorithm to compensate for any bias present. This second algorithm would perform countermeasures or compensate for the biases present to yield an overall unbiased system. What's more, AI could truly be used as a tool to increase the subjectivity in the human thought process if used adequately. Additionally, AI developers could reach out to the public, especially marginalized groups, during the design process to ensure a fair and equitable AI algorithm. 
                    </p>
                    <p>In the end, AI is a relatively new and evolving sector of knowledge that will generate new challenges while simultaneously improving human existence. What we know for certain is that the integration of advanced AI in our society will take the collaboration of policymakers, computer scientists, social scientists, the law, and the public to name a few. Certainly, it will be an enormous interdisciplinary effort.
                    </p>
                    <p>Danks, David, and Alex John London. "Algorithmic Bias in Autonomous Systems." IJCAI. Vol. 17. 2017.

                      Ferrer, Xavier, et al. "Bias and Discrimination in AI: a cross-disciplinary perspective." arXiv preprint arXiv:2008.07309 (2020).
                      
                      Howard, A., Borenstein, J. The Ugly Truth About Ourselves and Our Robot Creations: The Problem of Bias and Social Inequity. Sci Eng Ethics 24, 1521–1536 (2018). https://doi.org/10.1007/s11948-017-9975-2
                      
                      Zajko, M. Conservative AI and social inequality: conceptualizing alternatives to bias through social theory. AI & Soc (2021). https://doi.org/10.1007/s00146-021-01153-9
                      
                      Stanley-Lockman, Zoe, et al. Ethical Purpose: Ethics and Values. NATO Defense College, 2020, pp. 29–34, “NATO-Mation”: Strategies for Leading in the Age of Artificial Intelligence, www.jstor.org/stable/resrep27711.11. Accessed 25 Apr. 2021.
                      
                      Lemley, Mark A., and Bryan Casey. “Remedies for Robots.” The University of Chicago Law Review, vol. 86, no. 5, 2019, pp. 1311–1396. JSTOR, www.jstor.org/stable/26747441. Accessed 25 Apr. 2021.
                      
                      
                      </p>
          </figure>
        </div>
        <div class="col-md-5 mr-auto" data-aos="fade-up" data-aos-delay="">
  
  <!-- END section -->

  <!-- END .block-4 -->
  </div>

  

  
  <!-- END footer -->

  <!-- loader -->
  <div id="loader" class="show fullscreen"><svg class="circular" width="48px" height="48px">
      <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee" />
      <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
        stroke="#ffc107" /></svg></div>

  <script src="js/jquery-3.2.1.min.js"></script>
  <script src="js/jquery-migrate-3.0.1.min.js"></script>
  <script src="js/popper.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/owl.carousel.min.js"></script>
  <script src="js/jquery.waypoints.min.js"></script>
  <script src="js/jquery.fancybox.min.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/aos.js"></script>
  <script src="js/main.js"></script>
</body>

</html>